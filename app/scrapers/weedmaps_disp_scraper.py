from disp_filter import get_dispensary_filter
from jsonutils import loadJson, try_get_list
from weedmaps_helpers import WeedMapsDespensaryExtractor, WeedMapsDetailsExtractor
from runner import run
from httpclient import HttpClient
import json
import sys


class WeedMapsDispensaryScraper(object):
    def __init__(self, dispesary_filter, http_client):
        self._http_client = http_client
        self._weedmaps_disp_extractor = WeedMapsDespensaryExtractor(dispesary_filter,
                                                                    WeedMapsDetailsExtractor(HttpClient()))

        self._url = "https://api-g.weedmaps.com/wm/v2/location?include%5B%5D=regions.listings&region_slug={0}" \
                    "&page_size=150&page={1}"

    def produce(self, state):
        current_index = 1
        should_continue = True
        while should_continue:
            url = self._url.format(state.replace(' ', '-'), current_index)
            response = self._http_client.get(url)
            should_continue = False  # response.success
            if response.success:
                json_data = loadJson(response.content)
                listings = try_get_list(json_data, "data", "regions", "dispensary", "listings")
                if len(listings) == 0:
                    break
                for l in listings[0]:
                    url_list = try_get_list(l, "slug")
                    if len(url_list) > 0:
                        yield url_list[0]
                current_index = current_index + 1

    def consume(self, item_from_poroduce):
        url = self.reconstruct_url(item_from_poroduce)
        response = self._http_client.get(url)
        if response.success:
            json_data = loadJson(response.content)
            return self._weedmaps_disp_extractor.extract(json_data)
        return None

    def reconstruct_url(self, url_part):
        return "https://api-g.weedmaps.com/wm/web/v1/listings/" + url_part + "/menu?type=dispensary"


def scrape(arr):
    dispFilter = get_dispensary_filter(arr)
    wmScraper = WeedMapsDispensaryScraper(dispFilter, HttpClient())
    result = run(dispFilter.get_state_names(), wmScraper.produce, wmScraper.consume)

    return json.dumps(result)


if __name__ == "__main__":
    print (scrape(sys.argv[1:]))